{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "model2.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPp6SUKF9Q/iZQWwHXKboDI"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IOtCcWA7uL73",
        "colab_type": "text"
      },
      "source": [
        "Import dependancies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cLCm9ZN3s-DB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "import numpy as np\n",
        "import zipfile\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator      #For rescale images\n",
        "from tensorflow.python.keras.models import Sequential, Model\n",
        "from __future__ import division, absolute_import, print_function, unicode_literals\n",
        "from tensorflow.keras.utils import Sequence\n",
        "\n",
        "\n",
        "# Make sure tenserflow version is above 2.0\n",
        "try:\n",
        "  %tensorflow_version 2.x\n",
        "except Exvception:\n",
        "  pass"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kxd9JLWXuGe2",
        "colab_type": "text"
      },
      "source": [
        "Checking tensorflow version"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FAo7A7Jht_la",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "663ec428-516a-44b2-d3f6-1b4c0af4814e"
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.2.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H0Fh8wTiud3X",
        "colab_type": "text"
      },
      "source": [
        "Download the flower dataset and unzip it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lTu5wtacuFqm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "7f3b24b8-c8b4-4e6f-c400-48740956780c"
      },
      "source": [
        "_URL = \"https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\"\n",
        "\n",
        "zip_file = tf.keras.utils.get_file(origin=_URL, fname=\"flower_photos.tgz\", extract=True)\n",
        "base_dir = os.path.join(os.path.dirname(zip_file), 'flower_photos')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\n",
            "228818944/228813984 [==============================] - 4s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9NhWAXK4xBz0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_size=224      #Image_height and image_size setting to this value\n",
        "batch_size =64    #Batch size - Size of batches of data"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VIWlwJbhzM6q",
        "colab_type": "text"
      },
      "source": [
        "1.   Rescale images using ImageDataGenerator()\n",
        "2.   Create the train data generator and the validation data generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IraEAiBS0Rn5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "48e96efd-fa3f-4835-d2f4-001b18f39872"
      },
      "source": [
        "#  Rescaling images to same using ImageDataGenerator\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    validation_split=0.2\n",
        ")\n",
        "\n",
        "# Train data generator\n",
        "\n",
        "train_gen = datagen.flow_from_directory(\n",
        "    base_dir,     #train dataset directory\n",
        "    target_size = (img_size,img_size),      #image size (setting height and width)\n",
        "    batch_size=batch_size,      #size of batches of data\n",
        "    subset='training'     #subset of data (training)\n",
        ")\n",
        "\n",
        "# Validation data generator\n",
        "  # same procedure as train data generator\n",
        "\n",
        "val_gen = datagen.flow_from_directory(\n",
        "    base_dir,\n",
        "    target_size = (img_size,img_size),\n",
        "    batch_size=batch_size,\n",
        "    subset='validation'     #subset of data (validation)\n",
        ")\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 2939 images belonging to 5 classes.\n",
            "Found 731 images belonging to 5 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ebQmtMY52CnT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "8c30198d-509e-42db-a9ff-561744870d66"
      },
      "source": [
        "# extracting labels and image features from train data \n",
        "for image_batch , label_batch in train_gen:\n",
        "  break\n",
        "  \n",
        "print('Shepe of the image batch : ')\n",
        "print(image_batch.shape)\n",
        "print('Shepe of the label batch : ')\n",
        "print(label_batch.shape)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shepe of the image batch : \n",
            "(64, 224, 224, 3)\n",
            "Shepe of the label batch : \n",
            "(64, 5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QhGZ0YAI2xvx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a349b3da-c768-4c37-f890-5d96aa3186d3"
      },
      "source": [
        "print(train_gen.class_indices)      #checking class indices of train data"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'daisy': 0, 'dandelion': 1, 'roses': 2, 'sunflowers': 3, 'tulips': 4}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hGpyCgm021vz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# saving the labels to a file, for later usage\n",
        "labels = \"\\n\".join(sorted(train_gen.class_indices.keys()))\n",
        "with open('labels.txt','w') as f:\n",
        "  f.write(labels)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RTBorSY33PWN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "88084013-7697-4161-b404-7f615db3255a"
      },
      "source": [
        "!cat labels.txt     #view extracted labels in labels.txt"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "daisy\n",
            "dandelion\n",
            "roses\n",
            "sunflowers\n",
            "tulips"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K9f7koQr4FBl",
        "colab_type": "text"
      },
      "source": [
        "# Creating the base model with convnets\n",
        "\n",
        "For creating the base model we have used MobileNet V2 model from google. also used pre-trained dataset \"ImageNet\"\n",
        "\n",
        "Proforming \"Feature Extraction\"\n",
        "\n",
        "Base layaer will be our immidiate layer for feature extraction\n",
        "First, pick which intermediate layer of MobileNet V2 will be used for feature extraction. \n",
        "\n",
        "Excluding the top layer, classification layer is ideal.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eL6zQRME4CQI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "f55a2bb2-d53d-4a51-8210-a6b13bd34f4a"
      },
      "source": [
        "IMG_SHAPE = (img_size, img_size, 3)\n",
        "\n",
        "# Create the base model from the pre-trained model MobileNet V2\n",
        "base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,\n",
        "                                              include_top=False,      #excluding the classificaton layer\n",
        "                                              weights='imagenet')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
            "9412608/9406464 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1wgvdhIw7Etx",
        "colab_type": "text"
      },
      "source": [
        "# Feature extraction\n",
        "\n",
        "Freeze the conv base created as base_model to use it as the feature extractor.\n",
        "Then add classifer on top of it and train "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qzYXmR_d8Pkh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "base_model.trainable = False"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "223EIXY48rip",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Adding Classifrcation head\n",
        "model = tf.keras.Sequential([\n",
        "  base_model,\n",
        "  tf.keras.layers.Conv2D(32,3, activation ='relu'),\n",
        "  tf.keras.layers.Dropout(0.2),\n",
        "  tf.keras.layers.GlobalAveragePooling2D(),\n",
        "  tf.keras.layers.Dense(5, activation = 'softmax')\n",
        "])"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sn0V0XTi84Lm",
        "colab_type": "text"
      },
      "source": [
        "# Compile the model\n",
        "\n",
        "Compiling model before training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6O2ZzCNw81qH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer=tf.keras.optimizers.Adam(), \n",
        "              loss='categorical_crossentropy',      # loss function (because of many classes we have we used cateforical_crossentropy)\n",
        "              metrics=['accuracy'])       # asking for accuracy metrix"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EB2NBwh29-zd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "309c8ff7-bf83-4835-8af3-d67931b823fc"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "mobilenetv2_1.00_224 (Model) (None, 7, 7, 1280)        2257984   \n",
            "_________________________________________________________________\n",
            "conv2d (Conv2D)              (None, 5, 5, 32)          368672    \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 5, 5, 32)          0         \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d (Gl (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 5)                 165       \n",
            "=================================================================\n",
            "Total params: 2,626,821\n",
            "Trainable params: 368,837\n",
            "Non-trainable params: 2,257,984\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}